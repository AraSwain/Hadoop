- [Hadoop](#hadoop)
    + [Prerequisites](#prerequisites)
- [Getting Started with Hadoop](#getting-started-with-hadoop)
- [HDFS Architecture](#hdfs-architecture)
- [Map Reduce](#map-reduce)
- [YARN (MapReduce - 2)](#yarn--mapreduce---2-)
- [Hive](#hive)
- [Introduction](#introduction)
  * [HIVE Architecture](#hive-architecture)
  * [Partitioning](#partitioning)
    + [Static Partitioning](#static-partitioning)
    + [Dynamic Partitioning](#dynamic-partitioning)
  * [Bucketing](#bucketing)
  * [Index](#index)
- [PIG](#pig)
- [SQOOP](#sqoop)

# Hadoop
### Prerequisites
  Before starting this tutorial, we assume you know the basics of 
  * Core Java (OOPS concepts and Hands-on coding)
  * Database Concepts and SQL
  * Hands on with any  Linux Operating Systems and commands

# Getting Started with Hadoop
Hadoop is an open-source framework that allows to store and process huge amount of data in a distributed environment across clusters of cheap or commodity hardware. Hadoop is designed to scale up from single servers to thousands of servers, each offering local computation and storage. It is highly fault-tolerant.

Hadoop consists of the below two modules.
  * HDFS (Hadoop Distributed File System)
  * MapReduce

# HDFS Architecture

# Map Reduce

# YARN (MapReduce - 2)

# Hive
Hive is a data warehouse tool to process structured data in Hadoop. It built on top of MapReduce to process Big Data. It makes querying and analyzing as easy as SQL.

In this tutorial we will briefly discuss how to use Apache Hive and HQL (Hive Query Language) with HDFS (Hadoop Distributed File System).

# Introduction

## HIVE Architecture

## Partitioning
### Static Partitioning

### Dynamic Partitioning

## Bucketing

## Index
# PIG

# SQOOP
